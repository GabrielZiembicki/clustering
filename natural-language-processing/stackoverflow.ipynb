{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Conv1D, Dropout \n",
    "from keras.layers import Activation, GlobalMaxPool1D, Embedding, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_files('input/20news-18828')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dict(text=data['data'], target=data['target']))\n",
    "df['text'] = df['text'].apply(lambda x: x.decode('utf-8', errors='ignore'))\n",
    "df['text'] = df['text'].str.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'],\n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = LabelBinarizer()\n",
    "labeler.fit(y_train)\n",
    "y_train =labeler.transform(y_train)\n",
    "y_test = labeler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 1000\n",
    "num_labels = 20\n",
    "batch_size = 100\n",
    "\n",
    "token = Tokenizer(num_words=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 1, 6, 5], [7, 8, 9, 1, 1, 5], [2, 3, 4]]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx =['I like going to the cinema',\n",
    "     'Do you want to go to cinema',\n",
    "     'I like going shopping']\n",
    "\n",
    "tk = Tokenizer(num_words=10)\n",
    "tk.fit_on_texts(tx)\n",
    "tk.texts_to_sequences(tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "token.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tk = token.texts_to_matrix(X_train)\n",
    "X_test_tk = token.texts_to_matrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15062, 1000)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 128)               128128    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 137,684\n",
      "Trainable params: 137,684\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(vocab_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15062 samples, validate on 3766 samples\n",
      "Epoch 1/30\n",
      "15062/15062 [==============================] - 3s 172us/step - loss: 2.5333 - acc: 0.2210 - val_loss: 1.6294 - val_acc: 0.5502\n",
      "Epoch 2/30\n",
      "15062/15062 [==============================] - 2s 145us/step - loss: 1.5430 - acc: 0.5274 - val_loss: 1.0949 - val_acc: 0.6965\n",
      "Epoch 3/30\n",
      "15062/15062 [==============================] - 2s 133us/step - loss: 1.1555 - acc: 0.6425 - val_loss: 0.9403 - val_acc: 0.7175\n",
      "Epoch 4/30\n",
      "15062/15062 [==============================] - 2s 133us/step - loss: 0.9487 - acc: 0.7067 - val_loss: 0.8659 - val_acc: 0.7345\n",
      "Epoch 5/30\n",
      "15062/15062 [==============================] - 2s 136us/step - loss: 0.8288 - acc: 0.7420 - val_loss: 0.8432 - val_acc: 0.7408\n",
      "Epoch 6/30\n",
      "15062/15062 [==============================] - 2s 148us/step - loss: 0.7443 - acc: 0.7636 - val_loss: 0.8304 - val_acc: 0.7443\n",
      "Epoch 7/30\n",
      "15062/15062 [==============================] - 2s 135us/step - loss: 0.6597 - acc: 0.7921 - val_loss: 0.8199 - val_acc: 0.7467\n",
      "Epoch 8/30\n",
      "15062/15062 [==============================] - 2s 140us/step - loss: 0.6072 - acc: 0.8072 - val_loss: 0.8183 - val_acc: 0.7557\n",
      "Epoch 9/30\n",
      "15062/15062 [==============================] - 2s 143us/step - loss: 0.5524 - acc: 0.8255 - val_loss: 0.8161 - val_acc: 0.7520\n",
      "Epoch 10/30\n",
      "15062/15062 [==============================] - 2s 135us/step - loss: 0.5092 - acc: 0.8388 - val_loss: 0.8133 - val_acc: 0.7573\n",
      "Epoch 11/30\n",
      "15062/15062 [==============================] - 2s 143us/step - loss: 0.4724 - acc: 0.8506 - val_loss: 0.8301 - val_acc: 0.7541\n",
      "Epoch 12/30\n",
      "15062/15062 [==============================] - 2s 136us/step - loss: 0.4300 - acc: 0.8638 - val_loss: 0.8416 - val_acc: 0.7533\n",
      "Epoch 13/30\n",
      "15062/15062 [==============================] - 2s 148us/step - loss: 0.3954 - acc: 0.8723 - val_loss: 0.8583 - val_acc: 0.7594\n",
      "Epoch 14/30\n",
      "15062/15062 [==============================] - 2s 132us/step - loss: 0.3728 - acc: 0.8831 - val_loss: 0.8726 - val_acc: 0.7584\n",
      "Epoch 15/30\n",
      "15062/15062 [==============================] - 2s 133us/step - loss: 0.3551 - acc: 0.8875 - val_loss: 0.8761 - val_acc: 0.7565\n",
      "Epoch 16/30\n",
      "15062/15062 [==============================] - 2s 130us/step - loss: 0.3235 - acc: 0.8968 - val_loss: 0.8967 - val_acc: 0.7576\n",
      "Epoch 17/30\n",
      "15062/15062 [==============================] - 2s 131us/step - loss: 0.2989 - acc: 0.9059 - val_loss: 0.9139 - val_acc: 0.7581\n",
      "Epoch 18/30\n",
      "15062/15062 [==============================] - 2s 132us/step - loss: 0.2818 - acc: 0.9122 - val_loss: 0.9203 - val_acc: 0.7642\n",
      "Epoch 19/30\n",
      "15062/15062 [==============================] - 2s 129us/step - loss: 0.2684 - acc: 0.9165 - val_loss: 0.9396 - val_acc: 0.7592\n",
      "Epoch 20/30\n",
      "15062/15062 [==============================] - 2s 138us/step - loss: 0.2608 - acc: 0.9189 - val_loss: 0.9517 - val_acc: 0.7597\n",
      "Epoch 21/30\n",
      "15062/15062 [==============================] - 2s 126us/step - loss: 0.2487 - acc: 0.9210 - val_loss: 0.9494 - val_acc: 0.7608\n",
      "Epoch 22/30\n",
      "15062/15062 [==============================] - 2s 130us/step - loss: 0.2307 - acc: 0.9265 - val_loss: 0.9640 - val_acc: 0.7621\n",
      "Epoch 23/30\n",
      "15062/15062 [==============================] - 2s 133us/step - loss: 0.2246 - acc: 0.9300 - val_loss: 0.9875 - val_acc: 0.7623\n",
      "Epoch 24/30\n",
      "15062/15062 [==============================] - 2s 127us/step - loss: 0.2063 - acc: 0.9356 - val_loss: 1.0037 - val_acc: 0.7597\n",
      "Epoch 25/30\n",
      "15062/15062 [==============================] - 2s 126us/step - loss: 0.1976 - acc: 0.9365 - val_loss: 1.0283 - val_acc: 0.7621\n",
      "Epoch 26/30\n",
      "15062/15062 [==============================] - 2s 132us/step - loss: 0.1944 - acc: 0.9382 - val_loss: 1.0328 - val_acc: 0.7560\n",
      "Epoch 27/30\n",
      "15062/15062 [==============================] - 2s 152us/step - loss: 0.1781 - acc: 0.9442 - val_loss: 1.0594 - val_acc: 0.7589\n",
      "Epoch 28/30\n",
      "15062/15062 [==============================] - 2s 146us/step - loss: 0.1709 - acc: 0.9475 - val_loss: 1.0679 - val_acc: 0.7573\n",
      "Epoch 29/30\n",
      "15062/15062 [==============================] - 2s 143us/step - loss: 0.1648 - acc: 0.9474 - val_loss: 1.0876 - val_acc: 0.7576\n",
      "Epoch 30/30\n",
      "15062/15062 [==============================] - 2s 165us/step - loss: 0.1612 - acc: 0.9487 - val_loss: 1.0822 - val_acc: 0.7578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f1ea4c71b70>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_tk, y_train,\n",
    "          batch_size=batch_size,\n",
    "            epochs=30,\n",
    "            verbose=1,\n",
    "            validation_data=(X_test_tk, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3766/3766 [==============================] - 0s 55us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test_tk, y_test,\n",
    "                       batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict_classes(X_test_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-ce094bccd796>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.5653286e-06, 2.0513161e-04, 7.6242466e-04, ..., 1.1878647e-05,\n",
       "        4.0595558e-02, 2.6440969e-06],\n",
       "       [7.6336706e-12, 1.6679868e-14, 8.0282953e-16, ..., 9.9999547e-01,\n",
       "        2.3483155e-07, 9.3555697e-09],\n",
       "       [2.5373806e-16, 3.1428124e-06, 6.3270904e-02, ..., 3.5543592e-11,\n",
       "        1.4599913e-12, 1.7136658e-15],\n",
       "       ...,\n",
       "       [1.9486436e-07, 4.8299677e-07, 9.0094019e-08, ..., 6.4524244e-08,\n",
       "        8.6426475e-09, 3.7839712e-08],\n",
       "       [3.4799095e-17, 4.2828666e-14, 5.8623567e-17, ..., 5.0218187e-19,\n",
       "        2.9534169e-17, 1.8089481e-21],\n",
       "       [3.0622617e-04, 7.6196756e-04, 6.6908938e-04, ..., 1.7119993e-03,\n",
       "        1.3983354e-04, 3.9747477e-04]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 400\n",
    "embed_dim = 64\n",
    "filters = 16\n",
    "kernel = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], df['target'],\n",
    "                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "vocab_size = 5000\n",
    "num_labels = 20\n",
    "batch_size = 100\n",
    "\n",
    "token = Tokenizer(num_words=vocab_size)\n",
    "\n",
    "\n",
    "token.fit_on_texts(X_train)\n",
    "X_train = token.texts_to_sequences(X_train)\n",
    "X_test = token.texts_to_sequences(X_test)\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "X_train_sq = sequence.pad_sequences(X_train, maxlen=400)\n",
    "X_test_sq = sequence.pad_sequences(X_test, maxlen=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = LabelBinarizer()\n",
    "labeler.fit(y_train)\n",
    "y_train =labeler.transform(y_train)\n",
    "y_test = labeler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3766, 20)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3766, 400)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sq.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Conv1D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 400, 64)           320000    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 398, 16)           3088      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_6 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               2176      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 20)                1300      \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 334,820\n",
      "Trainable params: 334,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embed_dim, input_length=maxlen))\n",
    "model.add(Conv1D(filters=filters,\n",
    "                 kernel_size=kernel,\n",
    "                 padding='valid',\n",
    "                 strides=1,\n",
    "                 activation='relu'\n",
    "                ))\n",
    "model.add(MaxPool())\n",
    "model.add(Dense(128, input_shape=(vocab_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15062 samples, validate on 3766 samples\n",
      "Epoch 1/30\n",
      "15062/15062 [==============================] - 21s 1ms/step - loss: 2.8444 - acc: 0.1287 - val_loss: 2.2267 - val_acc: 0.3582\n",
      "Epoch 2/30\n",
      "15062/15062 [==============================] - 20s 1ms/step - loss: 1.7859 - acc: 0.4284 - val_loss: 1.3140 - val_acc: 0.6009\n",
      "Epoch 3/30\n",
      "15062/15062 [==============================] - 20s 1ms/step - loss: 1.2153 - acc: 0.5985 - val_loss: 1.0712 - val_acc: 0.6710\n",
      "Epoch 4/30\n",
      "15062/15062 [==============================] - 21s 1ms/step - loss: 0.9142 - acc: 0.6994 - val_loss: 0.9779 - val_acc: 0.6992\n",
      "Epoch 5/30\n",
      "15062/15062 [==============================] - 21s 1ms/step - loss: 0.6887 - acc: 0.7786 - val_loss: 0.9312 - val_acc: 0.7353\n",
      "Epoch 6/30\n",
      " 8300/15062 [===============>..............] - ETA: 9s - loss: 0.5501 - acc: 0.8228"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-5ca595e21510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             validation_data=(X_test_sq, y_test))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2665\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2667\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2649\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train_sq, y_train,\n",
    "          batch_size=batch_size,\n",
    "            epochs=30,\n",
    "            verbose=1,\n",
    "            validation_data=(X_test_sq, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
